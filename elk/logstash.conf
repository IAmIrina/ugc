input {
  # gelf {
  #   type => "docker"
  #   port => "5044"
  # }
  file {
      path => ["/var/log/nginx/access-log.json"]
      codec => "json"
      tags => ["nginx"]
    }
} 

output {
  # Разделить логи разных приложений по разным индексам можно с помощью простого if-else 
  if "nginx" in [tags] {
      elasticsearch {
        hosts => [ "${ES_HOST}" ]
        index => "nginx-%{+YYYY.MM.dd}"
      }
  } else {
      elasticsearch {
          hosts => [ "${ES_HOST}" ]
          index => "app-%{+YYYY.MM}"
      }
  }
} 








# input {
# # Данные поступят по UDP
#   udp {
#     port => "5044"
#   }
# }
# filter {  
# # Воспользуемся фильтром grok и разобьём строку на несколько полей
#     grok {
#         # Grok структурирует логи при помощи grok-шаблонов, выглядящих как %{PATTERN:ID}
#         # Под капотом каждого паттерна находится регулярное выражение. Это позволяет logstash понять, какие данные он должен найти в сообщении
#         # А ID задаёт название этому участку строки
#         # Список стандартных паттернов можно найти на github https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns
#         # Быстро протестировать корректность вашего паттерна можно в онлайн-отладчике https://grokdebug.herokuapp.com/

#         match => { "message" => "%{NUMBER:number1} %{NUMBER:number2} %{NUMBER:number3}" }
#   }
# }
# output {
# # Результат выведется в stdout
#   stdout {
#   }
#   elasticsearch {
#       hosts => [ "${ES_HOST}" ]
#   } 
# } 